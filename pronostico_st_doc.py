# -*- coding: utf-8 -*-
"""Pronostico ST doc.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/16jvlPWzzSrCTE9yprCWLAK-dGaI9T0PV
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
! pip install skforecast[full]

# Modelado y Forecasting
from xgboost import XGBRegressor
from sklearn.ensemble import RandomForestRegressor
from skforecast.ForecasterAutoreg import ForecasterAutoreg
from skforecast.model_selection import backtesting_forecaster
from skforecast.preprocessing import TimeSeriesDifferentiator
from sklearn.metrics import mean_absolute_error

#Carga de base desde almacenamiento local
from google.colab import files
uploaded = files.upload()

datos = pd.read_csv("AirPassengers.csv")
datos.info();
datos

#Convierte la columna Month a formato fecha y se elige dicha columna como indice. asfreq rellena con null si hay un salto de fecha por frecuencua mensual
datos['Month'] = pd.to_datetime(datos['Month'], format='%Y-%m')
datos = datos.set_index('Month')
datos = datos.asfreq('MS')
datos = datos.sort_index()
datos.head()

#validación si hay nulos es decir si la secuencia esta completa mes a mes
print(f'Número de filas con missing values: {datos.isnull().any(axis=1).mean()}')

#Grafica interactiva
import plotly.express as px

fig = px.line(datos.reset_index(), x = 'Month', y = '#Passengers',
              title = "Pasajeros de avión 1949-1970",
              labels = {'x': 'X-axis', 'y':'Y-axis'})

fig.show()

#Necesito graficos de correlación

#Siguiendo la regla de 70-30 se dividirá el conjunto de datos en 100 de entrenamiento y 44 de prueba
steps = 44
datos_train = datos[:-steps]
datos_test  = datos[-steps:]
print(f"Fechas train : {datos_train.index.min()} --- {datos_train.index.max()}  (n={len(datos_train)})")
print(f"Fechas test  : {datos_test.index.min()} --- {datos_test.index.max()}  (n={len(datos_test)})")

fig, ax = plt.subplots(figsize=(6, 2.5))
datos_train['#Passengers'].plot(ax=ax, label='train')
datos_test['#Passengers'].plot(ax=ax, label='test')
ax.legend();

# Crear y entrenar forecaster con el preprocesamiento de diferenciación

forecaster = ForecasterAutoreg(
                regressor = RandomForestRegressor(random_state=963),
                lags = 12,
                differentiation = 1 #para el caso de series de tiempo con tendencia positiva se incluye el preprocesamiento de diferenciación de primer grado
             )

forecaster.fit(y=datos_train['#Passengers'])
forecaster

# Predicciones

steps = 44
predicciones = forecaster.predict(steps=steps)
predicciones.head(5)

# Gráfico de predicciones vs valores reales

fig, ax = plt.subplots(figsize=(6, 2.5))
datos_train['#Passengers'].plot(ax=ax, label='train')
datos_test['#Passengers'].plot(ax=ax, label='test')
predicciones.plot(ax=ax, label='predicciones')
ax.legend();

# Error test
from sklearn.metrics import mean_squared_error
from sklearn.metrics import mean_absolute_error

error_mse = mean_squared_error(
                y_true = datos_test['#Passengers'],
                y_pred = predicciones
            )

error_mae = mean_absolute_error(
                y_true = datos_test['#Passengers'],
                y_pred = predicciones
)

print(f"Error de test (mse): {error_mse}")
print(f"Error de test (mae): {error_mae}")

# Búsqueda de hiperparámetros
from skforecast.model_selection import grid_search_forecaster
from skforecast.model_selection import backtesting_forecaster

steps = 44
forecaster = ForecasterAutoreg(
                regressor = RandomForestRegressor(random_state=963),
                lags      = 12, # Este valor será remplazado en el grid search
                differentiation = 1
             )

# Valores candidatos de lags
lags_grid = [6, 24]

# Valores candidatos de hiperparámetros del regresor
param_grid = {'n_estimators': [100, 500],
              'max_depth': [3, 5, 10]}

resultados_grid = grid_search_forecaster(
                        forecaster         = forecaster,
                        y                  = datos_train['#Passengers'],
                        param_grid         = param_grid,
                        lags_grid          = lags_grid,
                        steps              = steps,
                        refit              = False,
                        metric             = 'mean_squared_error',
                        initial_train_size = int(len(datos_train)*0.5),
                        fixed_train_size   = False,
                        return_best        = True,
                        n_jobs             = 'auto',
                        verbose            = False
                  )

# Resultados de la búsqueda de hiperparámetros

resultados_grid

# Crear y entrenar forecaster con mejores hiperparámetros

regressor = RandomForestRegressor(max_depth=5, n_estimators=100, random_state=963)
forecaster = ForecasterAutoreg(
                regressor = regressor,
                lags      = 24,
                differentiation = 1
             )

forecaster.fit(y=datos_train['#Passengers'])

# Predicciones

predicciones = forecaster.predict(steps=steps)

#Test de errores
error_mse = mean_squared_error(
                y_true = datos_test['#Passengers'],
                y_pred = predicciones
            )

error_mae = mean_absolute_error(
                y_true = datos_test['#Passengers'],
                y_pred = predicciones
)

print(f"Error de test (mse): {error_mse}")
print(f"Error de test (mae): {error_mae}")

# Gráfico de predicciones vs valores reales

fig, ax = plt.subplots(figsize=(6, 2.5))
datos_train['#Passengers'].plot(ax=ax, label='train')
datos_test['#Passengers'].plot(ax=ax, label='test')
predicciones.plot(ax=ax, label='predicciones')
ax.legend();

#Implementación y entrenamiento de modelo de pronostico con regresor Extreme Gradient Boosting
forecaster_gb = ForecasterAutoreg(
                    regressor       = XGBRegressor(random_state=963),
                    lags            = 12,
                    differentiation = 1
                )

#Entrenamiento
forecaster_gb.fit(y=datos_train['#Passengers'])

# Predicciones
predicciones_gb = forecaster_gb.predict(steps=steps)
predicciones_gb.head()

# Error test

error_mse_gb = mean_squared_error(
                y_true = datos_test['#Passengers'],
                y_pred = predicciones_gb
            )

error_mae_gb = mean_absolute_error(
                y_true = datos_test['#Passengers'],
                y_pred = predicciones_gb
)

print(f"Error de test xgb (mse): {error_mse_gb}")
print(f"Error de test xgb (mae): {error_mae_gb}")

# Gráfico de predicciones vs valores reales modelo xgb

fig, ax = plt.subplots(figsize=(6, 2.5))
datos_train['#Passengers'].plot(ax=ax, label='train')
datos_test['#Passengers'].plot(ax=ax, label='test')
predicciones_gb.plot(ax=ax, label='predicciones')
ax.legend();

#Busqueda de hiperparametros para regresor xgb
steps = 44
forecaster_gb = ForecasterAutoreg(
                regressor = XGBRegressor(random_state=963),
                lags      = 12, # Este valor será remplazado en el grid search
                differentiation = 1
             )

# Valores candidatos de lags
lags_grid = [6, 24]

# Valores candidatos de hiperparámetros del regresor
param_grid = {#'eta': [0.3, 0.6, 1],
              #'gamma': [0, 50, 144],
              'max_depth': [3, 5, 10]}

resultados_grid = grid_search_forecaster(
                        forecaster         = forecaster_gb,
                        y                  = datos_train['#Passengers'],
                        param_grid         = param_grid,
                        lags_grid          = lags_grid,
                        steps              = steps,
                        refit              = False,
                        metric             = 'mean_squared_error',
                        initial_train_size = int(len(datos_train)*0.5),
                        fixed_train_size   = False,
                        return_best        = True,
                        n_jobs             = 'auto',
                        verbose            = False
                  )

resultados_grid

# Crear y entrenar forecaster con regresos xgb con mejores hiperparámetros

regressor_gb = XGBRegressor(max_depth=3, random_state=963)
forecaster_gb = ForecasterAutoreg(
                regressor = regressor_gb,
                lags      = 24,
                differentiation = 1
             )

forecaster_gb.fit(y=datos_train['#Passengers'])

# Predicciones
predicciones_gb = forecaster_gb.predict(steps=steps)
predicciones_gb.head()

# Error test

error_mse_gb = mean_squared_error(
                y_true = datos_test['#Passengers'],
                y_pred = predicciones_gb
            )

error_mae_gb = mean_absolute_error(
                y_true = datos_test['#Passengers'],
                y_pred = predicciones_gb
)

print(f"Error de test xgb (mse): {error_mse_gb}")
print(f"Error de test xgb (mae): {error_mae_gb}")

# Gráfico de predicciones vs valores reales modelo xgb con hiperparametros eficientes

fig, ax = plt.subplots(figsize=(6, 2.5))
datos_train['#Passengers'].plot(ax=ax, label='train')
datos_test['#Passengers'].plot(ax=ax, label='test')
predicciones_gb.plot(ax=ax, label='predicciones')
ax.legend();

n = input()
print (n*n)

